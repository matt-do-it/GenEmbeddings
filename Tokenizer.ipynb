{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97442605-b566-49fa-b1c7-bf2c4085f7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "import os\n",
    "from transformers import Gemma3ForCausalLM, AutoTokenizer\n",
    "\n",
    "os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"]=\"0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88a8300-529b-4923-9dbe-b4a70a127205",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"./fused/gemma3-1b-it/transformers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158dbc9a-74eb-4d34-b8cc-8254b070e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test encoding\n",
    "test_text = \"This is a <unused0> example with <unused1>.\"\n",
    "encoded = tokenizer.encode(test_text, add_special_tokens=True)\n",
    "decoded = tokenizer.decode(encoded)\n",
    "print(\"Encoded IDs:\", encoded)\n",
    "print(\"Decoded text:\", decoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemma",
   "language": "python",
   "name": "gemma"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
